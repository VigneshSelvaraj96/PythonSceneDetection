{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3cc63b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d9c0437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the audio file\n",
    "audio_path = './Data/Ready_Player_One_rgb/InputAudio.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3c9d5479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 15.410430839002268), (15.410430839002268, 17.774104308390022), (17.774104308390022, 20.276394557823128), (20.276394557823128, 21.783968253968254), (21.783968253968254, 31.214036281179137), (31.214036281179137, 37.41743764172335), (37.41743764172335, 38.42569160997733), (38.42569160997733, 91.47480725623583), (91.47480725623583, 98.6391156462585), (98.6391156462585, 108.70587301587301), (108.70587301587301, 109.81174603174603), (109.81174603174603, 124.30213151927438), (124.30213151927438, 128.03045351473924), (128.03045351473924, 131.31315192743764), (131.31315192743764, 132.34945578231293), (132.34945578231293, 133.3499319727891), (133.3499319727891, 134.35009070294785), (134.35009070294785, 136.2178231292517), (136.2178231292517, 137.37401360544217), (137.37401360544217, 148.97195011337868), (148.97195011337868, 153.7806575963719), (153.7806575963719, 161.7739909297052), (161.7739909297052, 163.45249433106576), (163.45249433106576, 183.34367346938777), (183.34367346938777, 187.18238095238095), (187.18238095238095, 215.54002267573696), (215.54002267573696, 220.09274376417233), (220.09274376417233, 269.67054421768705), (269.67054421768705, 271.0100680272109), (271.0100680272109, 289.69)]\n"
     ]
    }
   ],
   "source": [
    "#The first experimentation I am doing here is to find out if this method works when we use on the entire project without start\n",
    "#and stop times.\n",
    "\n",
    "# Load the audio waveform WITHOUT start and stop times \n",
    "waveform, sample_rate = librosa.load(audio_path, sr=None)\n",
    "\n",
    "\n",
    "# Calculate the absolute difference between successive samples in the waveform\n",
    "diff = np.abs(np.diff(waveform))\n",
    "\n",
    "# Define the delta threshold above which a scene change is detected\n",
    "delta_threshold = np.sqrt(np.mean(np.square(waveform)))*2\n",
    "\n",
    "# Initialize the start and stop times list\n",
    "start_stop_times = []\n",
    "\n",
    "# Find the start and stop times for each scene change\n",
    "# im setting a 1 second minimum for audio classification here so it is not changing rapidly\n",
    "start = 0\n",
    "for i in range(1, len(diff)):\n",
    "    if diff[i] > delta_threshold:\n",
    "        stop = i / sample_rate\n",
    "        if(stop - start > 1): \n",
    "            start_stop_times.append((start, stop))\n",
    "            start = stop\n",
    "\n",
    "# Add the final scene if necessary\n",
    "if start < len(waveform) / sample_rate:\n",
    "    start_stop_times.append((start, len(waveform) / sample_rate))\n",
    "\n",
    "# Print the start and stop times list\n",
    "print(start_stop_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a6da20bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now this part of the experimentation is to find out if this menthod will work for start stop end times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1a2aac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start and stop times in seconds\n",
    "start_time = 5\n",
    "stop_time = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f90bcf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5.0, 11.72015873015873), (11.72015873015873, 14.16907029478458), (14.16907029478458, 15.357913832199547), (15.357913832199547, 17.77390022675737), (17.77390022675737, 18.78716553287982), (18.78716553287982, 20.0)]\n"
     ]
    }
   ],
   "source": [
    "# Load the audio waveform between the start and stop times\n",
    "waveform, sample_rate = librosa.load(audio_path, sr=None, offset=start_time, duration=stop_time-start_time)\n",
    "\n",
    "\n",
    "# Calculate the absolute difference between successive samples\n",
    "diff = np.abs(np.diff(waveform))\n",
    "\n",
    "# Define the delta threshold above which a shot change is detected. In our case, i decided to use RMS since we don't know the\n",
    "# avg change of waves without manual inspection. Professor will give us a random one anyway\n",
    "delta_threshold = np.sqrt(np.mean(np.square(waveform)))*2\n",
    "\n",
    "# Initialize the start and stop times list\n",
    "start_stop_times = []\n",
    "\n",
    "# Find the start and stop times for each scene change\n",
    "# im setting a 1 second minimum for audio classification here so it is not changing rapidly\n",
    "start = 0\n",
    "for i in range(1, len(diff)):\n",
    "    if diff[i] > delta_threshold:\n",
    "        # Use the sample index where the threshold is exceeded as the stop time\n",
    "        stop = i\n",
    "        if (stop - start) / sample_rate > 1:  # Minimum duration of 1 second\n",
    "            start_stop_times.append((start / sample_rate + start_time, stop / sample_rate + start_time))\n",
    "            start = i\n",
    "\n",
    "# Add the final scene if necessary\n",
    "if start < len(waveform):\n",
    "    stop = len(waveform)\n",
    "    if (stop - start) / sample_rate > 1:  # Minimum duration of 1 second\n",
    "        start_stop_times.append((start / sample_rate + start_time, stop / sample_rate + start_time))\n",
    "\n",
    "# Print the start and stop times list\n",
    "print(start_stop_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d881c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
